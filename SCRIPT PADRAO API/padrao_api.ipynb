{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def obterNota(token, exercicio: int, pagina: int, totalRegistroPagina=5000):\n",
    "    try:\n",
    "        dados_totais = []  # Lista para armazenar os dados de todas as páginas\n",
    "\n",
    "        while True:\n",
    "            url = f\"https://tesouro.sefaz.pi.gov.br/siafe-api/nota-empenho/{exercicio}/{pagina}/{totalRegistroPagina}\"\n",
    "            headers = {\"Content-Type\": \"application/json\", \"Authorization\": token}\n",
    "            \n",
    "            data = {\n",
    "                \"dataInicio\": \"2024-01-01\",\n",
    "                \"dataFim\": \"2024-12-31\",\n",
    "            }\n",
    "            data = json.dumps(data)\n",
    "                    \n",
    "            resposta = requests.post(url=url, headers=headers, data=data)\n",
    "            resposta.raise_for_status()\n",
    "    \n",
    "            if resposta.status_code == 200:\n",
    "                dados_resposta = resposta.json()\n",
    "            \n",
    "                \n",
    "                # Listas para armazenar os dados\n",
    "                dados_classificadores = []\n",
    "                dados = []\n",
    "                \n",
    "                # Palavras-chave para filtragem\n",
    "                palavras_chave = [\"primeira infância\", \"pacto pelas crianças\", \"infância\", \"infantil\", \"criança\", \"creche\", \"carretinha\", \"primeira infancia\", \"pacto pelas criancas\", \"infancia\", \"crianca\"]\n",
    "                \n",
    "                for dado in dados_resposta.get('registros', []):\n",
    "                    if isinstance(dado, dict):\n",
    "                        campopalavras = dado.get('observacao', '-').lower()\n",
    "                        if any(re.search(re.escape(palavra), campopalavras) for palavra in palavras_chave):\n",
    "                            # Coletando dados dos classificadores\n",
    "                            classificadores_dict = {'id': dado['id']}\n",
    "                            for classificador in dado['classificadores']:\n",
    "                                classificadornome = classificador['nomeTipoClassificador']\n",
    "                                if classificadornome == 'Unidade Orçamentária':\n",
    "                                    classificadores_dict[classificador['nomeTipoClassificador']] = classificador['nomeClassificador']\n",
    "                            dados_classificadores.append(classificadores_dict)\n",
    "                            \n",
    "                            # Coletando dados da ação\n",
    "                            dados.append({\n",
    "                                'id': dado['id'],\n",
    "                                'codigo': dado['codigo'],\n",
    "                                'codContrato': dado['codContrato'],\n",
    "                                'observacao': dado['observacao'],\n",
    "                            })\n",
    "                    else:\n",
    "                        print(\"NENHUMA PALAVRA CHAVE ENCONTRADA\")\n",
    "                            \n",
    "                # Criando DataFrames\n",
    "                df_classificadores = pd.DataFrame(dados_classificadores)\n",
    "                df_dados = pd.DataFrame(dados)\n",
    "    \n",
    "                # Mesclando os DataFrames\n",
    "                df_merged = pd.merge(df_classificadores, df_dados, on='id')\n",
    "                \n",
    "                # Adicionando os dados da página atual à lista de dados totais\n",
    "                dados_totais.append(df_merged)\n",
    "                \n",
    "                if not dados_resposta.get(\"possuiProximaPagina\"):\n",
    "                    break\n",
    "                \n",
    "                pagina += 1\n",
    "                print(f'pagina atual: {pagina}')\n",
    "                    \n",
    "        # Concatenando todos os DataFrames em um único DataFrame\n",
    "        df_final = pd.concat(dados_totais, ignore_index=True)\n",
    "        \n",
    "        # Salvar o DataFrame geral em um arquivo Excel\n",
    "        nome_arquivo = f\"Arquivo{exercicio}.xlsx\"\n",
    "        df_final.to_excel(nome_arquivo, index=False)\n",
    "        print(f\"Arquivo '{nome_arquivo}' foi criado com sucesso!\")\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"Erro HTTP: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante a organização dos dados: {e}\")\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    token = 'eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJBUEkgZGUgSW50ZWdyYcOnw6NvIExvZ3VzIiwic3ViIjoiNjIyNjUxMDgzODMiLCJpYXQiOjE3MTQ0Nzk1NjcsImV4cCI6MTcxNDU2NTk2N30.Zriog08Fj3piMnO2lNcHhGimxoTTeiKT7C8YDfNUYe4'\n",
    "    exercicio = 2024\n",
    "    pagina = 1\n",
    "\n",
    "    obterNota(token, exercicio=exercicio, pagina=pagina)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
